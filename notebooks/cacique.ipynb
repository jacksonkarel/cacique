{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/cacique/blob/main/notebooks/cacique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "517a9fd4",
      "metadata": {
        "id": "517a9fd4"
      },
      "source": [
        "# BabyAGI with Tools\n",
        "\n",
        "This notebook builds on top of [baby agi](baby_agi.ipynb), but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556af556",
      "metadata": {
        "id": "556af556"
      },
      "source": [
        "## Install and Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "id": "u1zssthM_ge5"
      },
      "id": "u1zssthM_ge5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sj5t6OIPpBFl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "sj5t6OIPpBFl"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/Datasets/* ."
      ],
      "metadata": {
        "id": "L4Dh5i-Irc5i"
      },
      "execution_count": null,
      "outputs": [],
      "id": "L4Dh5i-Irc5i"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "76rxB60EqgoI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "76rxB60EqgoI"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "W1IsL1SWuJsx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W1IsL1SWuJsx"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "keys = json.load(open('keys.json'))\n",
        "os.environ[\"OPENAI_API_KEY\"] = keys['openai']\n",
        "os.environ[\"SERPAPI_API_KEY\"] = keys['serp']"
      ],
      "metadata": {
        "id": "_cOQsfaL5vim"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_cOQsfaL5vim"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm keys.json"
      ],
      "metadata": {
        "id": "fiiemgHe4yET"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fiiemgHe4yET"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a354b6",
      "metadata": {
        "id": "c8a354b6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "from langchain import LLMChain, OpenAI, PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import BaseLLM\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.chains.base import Chain\n",
        "from langchain.experimental import BabyAGI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f70772",
      "metadata": {
        "id": "09f70772"
      },
      "source": [
        "## Connect to the Vector Store\n",
        "\n",
        "Depending on what vectorstore you use, this step may look different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794045d4",
      "metadata": {
        "id": "794045d4"
      },
      "outputs": [],
      "source": [
        "%pip install faiss-cpu > /dev/null\n",
        "%pip install google-search-results > /dev/null\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore import InMemoryDocstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0305eb",
      "metadata": {
        "id": "6e0305eb"
      },
      "outputs": [],
      "source": [
        "# Define your embedding model\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "# Initialize the vectorstore as empty\n",
        "import faiss\n",
        "\n",
        "embedding_size = 1536\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43cd580",
      "metadata": {
        "id": "b43cd580"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from langchain.utilities import PythonREPL\n",
        "\n",
        "todo_prompt = PromptTemplate.from_template(\n",
        "    \"You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}\"\n",
        ")\n",
        "todo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=todo_prompt)\n",
        "search = SerpAPIWrapper()\n",
        "python_repl = PythonREPL()\n",
        "tools = [\n",
        "    # Tool(\n",
        "    #     name=\"Search\",\n",
        "    #     func=search.run,\n",
        "    #     description=\"useful for when you need to answer questions about current events\",\n",
        "    # ),\n",
        "    Tool(\n",
        "        name=\"TODO\",\n",
        "        func=todo_chain.run,\n",
        "        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Python REPL\",\n",
        "        func=python_repl.run,\n",
        "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "prefix = \"\"\"You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\"\"\"\n",
        "suffix = \"\"\"Question: {task}\n",
        "{agent_scratchpad}\"\"\"\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "fSj0YSuHJ3Pa"
      },
      "id": "fSj0YSuHJ3Pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b00ae2e",
      "metadata": {
        "id": "4b00ae2e"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "tool_names = [tool.name for tool in tools]\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ba762e",
      "metadata": {
        "id": "05ba762e"
      },
      "source": [
        "### Run the BabyAGI\n",
        "\n",
        "Now it's time to create the BabyAGI controller and watch it try to accomplish your objective."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"LivingPlanetIndex2022_public.csv\")\n",
        "print(list(df.columns))"
      ],
      "metadata": {
        "id": "RSqWlkjdvyh1"
      },
      "id": "RSqWlkjdvyh1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d220b69",
      "metadata": {
        "id": "3d220b69"
      },
      "outputs": [],
      "source": [
        "OBJECTIVE = \"Each row is a different species, give a list of species that match the Location the Region of the mouth of the Karipunas River in the Madeira River in the LivingPlanetIndex2022_public.csv dataset. Summarize the information for a biodiversity expert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d69899b",
      "metadata": {
        "id": "3d69899b"
      },
      "outputs": [],
      "source": [
        "# Logging of LLMChains\n",
        "verbose = False\n",
        "# If None, will keep on going forever\n",
        "max_iterations: Optional[int] = 3\n",
        "baby_agi = BabyAGI.from_llm(\n",
        "    llm=llm, vectorstore=vectorstore, task_execution_chain=agent_executor, verbose=verbose, max_iterations=max_iterations\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7957b51",
      "metadata": {
        "scrolled": false,
        "id": "f7957b51"
      },
      "outputs": [],
      "source": [
        "baby_agi({\"objective\": OBJECTIVE})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OBJECTIVE = \"Find the answer to the question how many of each of these species were observed in column 2022?\""
      ],
      "metadata": {
        "id": "YspaLFvp6I57"
      },
      "id": "YspaLFvp6I57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_iterations: Optional[int] = 1\n",
        "baby_agi = BabyAGI.from_llm(\n",
        "    llm=llm, vectorstore=vectorstore, task_execution_chain=agent_executor, verbose=verbose, max_iterations=max_iterations\n",
        ")"
      ],
      "metadata": {
        "id": "1jeDh1-i7y4k"
      },
      "id": "1jeDh1-i7y4k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baby_agi({\"objective\": OBJECTIVE})"
      ],
      "metadata": {
        "id": "g4SbRAZv6hqN"
      },
      "id": "g4SbRAZv6hqN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}