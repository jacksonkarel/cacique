{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacksonkarel/cacique/blob/main/notebooks/cacique_baby_agi_with_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "517a9fd4",
      "metadata": {
        "id": "517a9fd4"
      },
      "source": [
        "# BabyAGI with Tools\n",
        "\n",
        "This notebook builds on top of [baby agi](baby_agi.ipynb), but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556af556",
      "metadata": {
        "id": "556af556"
      },
      "source": [
        "## Install and Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai"
      ],
      "metadata": {
        "id": "u1zssthM_ge5"
      },
      "id": "u1zssthM_ge5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8a354b6",
      "metadata": {
        "id": "c8a354b6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "from langchain import LLMChain, OpenAI, PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import BaseLLM\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.chains.base import Chain\n",
        "from langchain.experimental import BabyAGI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f70772",
      "metadata": {
        "id": "09f70772"
      },
      "source": [
        "## Connect to the Vector Store\n",
        "\n",
        "Depending on what vectorstore you use, this step may look different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794045d4",
      "metadata": {
        "id": "794045d4"
      },
      "outputs": [],
      "source": [
        "%pip install faiss-cpu > /dev/null\n",
        "%pip install google-search-results > /dev/null\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore import InMemoryDocstore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "A4wBX7plBBIs"
      },
      "id": "A4wBX7plBBIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "keys = json.load(open('keys.json'))\n",
        "os.environ[\"OPENAI_API_KEY\"] = keys['openai']\n",
        "os.environ[\"SERPAPI_API_KEY\"] = keys['serp']"
      ],
      "metadata": {
        "id": "mf5_8cQFBDym"
      },
      "id": "mf5_8cQFBDym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0305eb",
      "metadata": {
        "id": "6e0305eb"
      },
      "outputs": [],
      "source": [
        "# Define your embedding model\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "# Initialize the vectorstore as empty\n",
        "import faiss\n",
        "\n",
        "embedding_size = 1536\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3b72bf",
      "metadata": {
        "id": "0f3b72bf"
      },
      "source": [
        "## Define the Chains\n",
        "\n",
        "BabyAGI relies on three LLM chains:\n",
        "- Task creation chain to select new tasks to add to the list\n",
        "- Task prioritization chain to re-prioritize tasks\n",
        "- Execution Chain to execute the tasks\n",
        "\n",
        "\n",
        "NOTE: in this notebook, the Execution chain will now be an agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43cd580",
      "metadata": {
        "id": "b43cd580"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from langchain.utilities import PythonREPL\n",
        "\n",
        "todo_prompt = PromptTemplate.from_template(\n",
        "    \"You are a planner who is an expert at coming up with a todo list for a given objective. Come up with a todo list for this objective: {objective}\"\n",
        ")\n",
        "todo_chain = LLMChain(llm=OpenAI(temperature=0), prompt=todo_prompt)\n",
        "search = SerpAPIWrapper()\n",
        "python_repl = PythonREPL()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"TODO\",\n",
        "        func=todo_chain.run,\n",
        "        description=\"useful for when you need to come up with todo lists. Input: an objective to create a todo list for. Output: a todo list for that objective. Please be very clear what the objective is!\",\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Python REPL\",\n",
        "        func=python_repl.run,\n",
        "        description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "prefix = \"\"\"You are an AI who performs one task based on the following objective: {objective}. Take into account these previously completed tasks: {context}.\"\"\"\n",
        "suffix = \"\"\"Question: {task}\n",
        "{agent_scratchpad}\"\"\"\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"objective\", \"task\", \"context\", \"agent_scratchpad\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "fSj0YSuHJ3Pa"
      },
      "id": "fSj0YSuHJ3Pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b00ae2e",
      "metadata": {
        "id": "4b00ae2e"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "tool_names = [tool.name for tool in tools]\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ba762e",
      "metadata": {
        "id": "05ba762e"
      },
      "source": [
        "### Run the BabyAGI\n",
        "\n",
        "Now it's time to create the BabyAGI controller and watch it try to accomplish your objective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d220b69",
      "metadata": {
        "id": "3d220b69"
      },
      "outputs": [],
      "source": [
        "OBJECTIVE = \"Create a biodiversity index for San Francisco\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d69899b",
      "metadata": {
        "id": "3d69899b"
      },
      "outputs": [],
      "source": [
        "# Logging of LLMChains\n",
        "verbose = False\n",
        "# If None, will keep on going forever\n",
        "max_iterations: Optional[int] = None\n",
        "baby_agi = BabyAGI.from_llm(\n",
        "    llm=llm, vectorstore=vectorstore, task_execution_chain=agent_executor, verbose=verbose, max_iterations=max_iterations\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7957b51",
      "metadata": {
        "scrolled": false,
        "id": "f7957b51"
      },
      "outputs": [],
      "source": [
        "baby_agi({\"objective\": OBJECTIVE})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}